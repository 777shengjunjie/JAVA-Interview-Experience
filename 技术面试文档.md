---
title 技术面试文档
categories:
- shengjunjie
tags:
-  
---


<!--more-->


### *争对项目的问题
1.为什么使用在shiro中基于redis
如果使用nginx进行代理，可能会出现在两次登录过程中，第二次所访问的服务器不是第一次访问的服务器，导致无法认证当前状态是否属于已经登录，那么后续的操作也将无法访问呢。

### 第一章 数据库
#### 1.数据库中的索引
数据库的索引是用于加快数据的查询速度，索引分为聚簇索引与非聚簇索引。我们通常使用的InnoDB引擎，属于聚簇索引，他的数据查询主要依靠主键索引以及辅助索引，其底层的实现是B+树,叶子节点存储的是数据，通过主键索引可以直接查询到档当前的数据，辅助索引的叶子节点存储了主键的key，如果想查询其他数据，他需要借助主键索引；而MyISAM的索引结构数据非聚簇索引，他的仍是B+树为底层，只不过其叶子节点存储的是数据的物理地址，其需要通过地址访问数据。
#### 2.Mysql实现在A表不在B表的语句
select * from A where id not in (select id from B)

#### 3.Mysql性能优化-索引
1. 在查询的语句的时候，尽量使用全部的复合索引
2. 最佳左前缀法则
3. 不要做一下操作 计算，如：
    +、-、*、/、!=、<>、is null、is not null、or
    函数，如：sum()、round()等等
    手动/自动类型转换，如：id = "1"，本来是数字，给写成字符串了
4. 索引不要放在范围查询的右边
5. 减少使用select * ，使用覆盖索引查询。即：select 查询字段和 where 中使用的索引字段一致。
6. 对于like模糊查询
    * 失效情况
    1. like "%张三%"
    2. like "%张三"
    * 解决方案
    使用复合索引，即 like 字段是 select 的查询字段，如：select name from table where name like "%张三%"使用 like "张三%"


#### 4.innodb默认的事务隔离级别
可重复读。(读已提交与可重复读的快照读都是基于MVCC实现的)
* 它的实现原理主要是版本链，undo日志 ，Read View来实现的

RC、RR级别下的InnoDB快照读区别
* 在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；

* 即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见

* 而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因
此外原子性undolog实现，持久性redolog实现，隔离性通过加锁与Mvvc

### 第二章 Redis

### 第三章 Java基础
#### 1.内存分配的方式
* 程序计数器:记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。
* Java 虚拟机栈:每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
* 本地方法栈：本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理
* 堆：所有对象都在这里分配内存，是垃圾收集的主要区域（"GC 堆"）。现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。
* 方法区：用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。

### 第四章 网络
#### 1.tcp的概念
tcp属于传输层，是一种面向连接的传输协议，提供可靠的交付，能够进行流量控制，拥塞控制，提供全双工通信，面向字节流，每一条tcp连接只能是点对点。
#### 2.三次握手（三次握手改成二次或者四次会怎么样）
* 当A向B发送请求，此时会将同步位SYN为1，并选择序号seq=x,代表传输的数据第一个数据字节的序号为x；当B接受到报文请求后，会将SYN=1、确认值 ACK=1置为1，确认号ack=x+1,选择序号seq=y;A收到此报文后会向B发送请求，此时ACK=1,ack=y+1;seq=x+1,当确认结束后将SYN=0;
* 1.两次握手无法判断当前连接是否是历史连接（序列号过期或者超时）。如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接；如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接；2.(无法同步双方初始序列号) 只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。3.由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源。
* 四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。
#### 3.四次挥手
A向B发出请求，此时会将FIN=1,seq=u;此时B收到请求，将会向A发送报文，其中ACK=1,ack=U+1，seq=v;这时TCP服务器进程通知高层应用进程，从A到B这个放向的连接就释放了，Tcp的连接处于半关闭状态。B若发送数据，A仍要接收。若B已经没有向A发送的数据，其应用进程就通知TCP释放连接。此时B向A发送释放连接的请求，ACK=1,FIN=1,seq=w,ack=u+1;当A收到这段报文后，必须发出确认。ACK=1,ack=w+1;seq=u+1;同时要注意此时A要等待2MSL的时间，确保A发送的最后一个请求能够到达A端，还能防止“已失效的连接请求报文段”出现在下一次请求中。
#### 4.Web的网页请求流程
* 通过DHCP动态主机配置协议，层层访问默认网关路由器，为主机申请IP。
* 基于ARP地址转换协议，查找默认网关路由器的MAC地址
* 基于DNS域名系统，去查找目的域名的IP，首先：1.先从浏览器缓存里找IP,因为浏览器会缓存DNS记录一段时间。2.如没找到,再从Hosts文件查找是否有该域名和对应IP。3.如没找到,再从路由器缓存找4.如没好到,再从DNS缓存查找5.如果都没找到,浏览器域名服务器向根域名服务器(http://baidu.com)查找域名对应IP,还没找到就把请求转发到下一级,直到找到IP
* 建立TCP三次握手的请求连接，将请求报文放入套接字，网络层、数据链路层，层层封装，最终经过以太网路由转发给目的服务器
* 服务器收到请求后，返回响应报文，本地主机接收到响应报文之后，经由浏览器渲染展示。
#### 5.ARP协议的作用以及使用方法
* ARP协议是根据IP地址获取物理地址的一个TCP/IP协议。主机将包含包含目标主机ip地址的ARP请求发送到网络上的所有主机，接受返回的消息，用于确定目标的物理地址；收到返回消息后将ARP与MAC地址映射到本机的ARP缓存中，一边下次访问节省时间。
#### 6.TCP协议的滑动窗口
窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过TCP报文字段中的窗口字段告诉发送方自己窗口大小，而发送方根据这个值和其他数值对自己的窗口大小进行设置。当发送方的一部分数据被发送时，他的滑动窗口向右移动一部分，接受窗口也是同样的道理，当异步数据接收被确认时，窗口向右滑动，同时要注意接受窗口内只会对最后一个按序到达的字节进行确认，比如{31，34，35}，接收方只对31进行却等，发送方得到一个字节后，可以指导这个字节之前的数据已经全部被接收。
#### 7.Select和poll以及epoll使用场景,以及epoll中的ET和LT
|         | select    |  poll           |  epoll  |
| --------| -----:   | :----:           |-----  |
| FD数量   | 1024      |   无限制         |无限制  |
| FD状态感知| 轮询     |   轮询             |事件通知|
| 重置数据源| 需要     |   不需要（event/revent）|通知就绪的|
| 运行模式|条件触发（LT）|条件触发（LT）|边缘触发（ET）/条件触发(LT)|
poll:Struct pollfd
select:bitMap
epoll:
* epoll_create():内核态创建epoll实例（红黑树与就绪队列rdlist）
* epoll_ctl:对红黑树操作，添加所有socket节点
* epoll_wait:1.阻塞线程2.内核查找红黑树ready的socket，放入就绪列表3.将就绪列表内容复制到events。
* events[i].data.fd;处理socket
条件触发：当读取一半数据时，干别的事情，条件触发在下次会重新读取，但是边缘处触发不会，只会读取一次。条件触发：不会触发遗漏事件，系统资源占用大 边缘触发：速度快，但会出现遗漏事件；nginx:ET;redis:LT
简单来讲，LT是epoll的默认操作模式，当epoll_wait函数检测到有事件发生并将通知应用程序，而应用程序不一定必须立即进行处理，这样epoll_wait函数再次检测到此事件的时候还会通知应用程序，直到事件被处理。



而ET模式，只要epoll_wait函数检测到事件发生，通知应用程序立即进行处理，后续的epoll_wait函数将不再检测此事件。因此ET模式在很大程度上降低了同一个事件被epoll触发的次数，因此效率比LT模式高。



解释为什么epoll默认是LT的原因

LT(level triggered)：LT是缺省的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。
#### 8.DNS服务器原理
DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用UDP进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：
* 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。
* 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。
#### 9.如何保证数据的实时性

* 降低排队时延：分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。
* 处理时延：主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路
由等。
* 传输时延：主机或路由器传输数据帧所需要的时间。
* 传播时延：电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速
#### 10.http协议的错误码
400 Bad Request：请求语法出错
401 Unauthorized:认证未通过
403 Forbidden:请求被拒绝
404 Not Found
500 Internal Server Error:服务器正在执行请求时发生错误。
503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

### 第五章 操作系统
#### 1.操作系统的内存管理
包括：内存分配、地址映射、内存保护与共享、虚拟内存；操作系统为了管理内存，其需要将内存抽象为地址空间。每个程序拥有自己的地址空间，地址空间又被分为多个页，这些页被映射到物理内存，但不需要将全部的存储到物理内存中，当程序引用到的内存不在物理内存中存在时，由硬件执行必要的映射，将缺失的部分装入到物理内存中，进行重新执行。从而使在有限的内存中运行大程序成为了可能性。
（虚拟内存：用于让物理内存扩充成更大的逻辑内存，从而让程序获得更多可用的内存。）
#### 2.操作系统的文件管理系统
文件系统是操作系统中负责管理持久数据的子系统，说简单点，就是负责把用户的文件存到磁盘硬件中，因为即使计算机断电了，磁盘里的数据并不会丢失，所以可以持久化的保存文件。文件系统的基本单位时文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。对于Linux系统会为文件非陪两个数据结构：索引节点间和目录项。
* 索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。
* 目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。

由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。

#### 3.进程通讯的常用方式
* 管道
* FIFO命名管道：去除了管道只能在父子进程中使用的限制。
* 消息队列：
1.消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
2.避免了FIFO的同步阻塞问题，不需要进程自己提供同步方法；
3.读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。
* 信号量
* 共享存储
* 套接字：与其它通信机制不同的是，它可用于不同机器间的进程通信。
#### 4.操作系统中常用的调度算法
1. 批处理系统 
批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。
* 针对批处理系统：先来先服务、短作业优先、最短剩余时间优先
2. 交互式系统 
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
* 针对交互式系统：时间片轮转、优先级调度、多级反馈队列
3. 实时系统 
实时系统要求一个请求在一个确定时间内得到响应。
分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。
#### 5.如何避免死锁
* 鸵鸟策略：操作系统当作没看到
* 死锁检测与死锁恢复：
1.死锁检测：每种类型一个资源的死锁检测；每种类型多个资源的死锁检测
2.死锁恢复 ：利用抢占恢复；利用回滚恢复；通过杀死进程恢复
* 死锁预防
1.破环互斥
2.破环占有和等待
3.破环不可抢占
4.破环循环等待
* 死锁避免
1.安全状态
2.单个资源的银行家算法
3.多个资源的银行家算法
#### 6.进程、线程
* 进程是资源分配的基本单位。
进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行态，所谓的创建进程和撤销进程，都是指对PCB 的操作。
* 线程是独立调度的基本单位。
一个进程中可以有多个线程，它们共享进程资源。QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程
的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。
* 区别 
Ⅰ 拥有资源
进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
Ⅱ 调度
线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程
中的线程时，会引起进程切换。
Ⅲ 系统开销
 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销
线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而
线程切换时只需保存和设置少量寄存器内容，开销很小。
Ⅳ 通信方面
线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC
#### 7.页存储器、段式存储器、段页式存储器以及分配原理
分页与分段的比较:
* 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
* 地址空间的维度：分页是一维地址空间，分段是二维的。
* 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
* 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护

段页式：
* 程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。
段页式内存管理实现的方式：

先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；

接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由段号、段内页号和页内位移三部分组成。

段页式地址变换中要得到物理地址须经过三次内存访问：

第一次访问段表，得到页表起始地址；

第二次访问页表，得到物理页号；

第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。
#### 8.页面置换算法
* 最佳算法
* LRU
* NRU：维护一个R与M状态位，其中R=1是最近访问过，M=1是修改过
* FIFO：缺陷可能会把经常访问的页面置换出去
* 第二次机会算法：结合了FIFO与NRU,如果该页面的R=1则将其R=0,放入末尾，否则的R=1时直接置换。
* 时钟算法：第二次机会算法需要在页表中移动页面，其采用环形链表将页面连接起来，在通过指针指向最老的页面


### 第六章 Linux
1. lsof -i:端口号
2. netstat -nltp | grep 端口号

### 第七章 设计模式
#### 1.设计模式的六大原则
* 开闭原则 
* 单一原则
* 里氏替换原则
* 依赖倒置原则
* 迪米特原则
* 接口隔离原则
#### 2.常用的设计模式
单例模式、策略模式、代理模式等
```java
//单例模式
public class Singleton{
    private staitc volatile Singleton instace=null;
    private Singleton(){

    }
    public static Singleton getInstance(){
        if(instance == null){
            synchronized(Sington.class){
                if(instance == null){
                    instacce=new Singleton();
                }
            }
        }
        return instace;
    }
}
```

### 第八章 JAVA多线程
#### 1.多线程编程中如何实现资源同步
* synchronized与同步代码块
* Lock
* cas与Volatile
* TreadLocal
#### 2.线程间的同步和通信怎么实现的
 线程之间是共享内存的，他们之间是可以直接通讯的，同步有临界区、自旋锁、等待与唤醒，屏障
* synchronized wait/notify
* sleep join/yield
* park/unpark
* threadLocal
#### 3.volatile的特性？Synchronized的锁升级过程？Synchronized是重量级锁，重量体现在哪里，轻量级锁轻量体现在哪里？
* volatile能够实现可见性与有序性
* synchronized 锁升级的过程：（无锁->偏向锁->轻量级锁->重量级锁）
1.在锁对象的对象头里面有一个 threadid 字段，未访问时 threadid 为空
2.第一次访问 jvm 让其持有偏向锁，并将 threadid 设置为其线程 id
3.再次访问时会先判断 threadid 是否与其线程 id 一致。如果一致则可以直接使用此对象；如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁
4.执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁
* 当一个线程获得重量级锁之后，其余所有等待获取该锁的线程都会进入到阻塞状态
* 当锁是偏向锁的的时候，此时线程B对该锁进行访问，此时偏向锁会升级为轻量级锁，线程B会通过自旋的形式获取该锁，线程不会阻塞，从而提高性能。
![锁区别](/assets/锁区别.png)

#### 4.锁的分类
无锁：没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功，其他修改失败的线程会不断重试直到修改成功。

偏向锁：对象的代码一直被同一线程执行，不存在多个线程竞争，该线程在后续的执行中自动获取锁，降低获取锁带来的性能开销。偏向锁，指的就是偏向第一个加锁线程，该线程是不会主动释放偏向锁的，只有当其他线程尝试竞争偏向锁才会被释放。

偏向锁的撤销，需要在某个时间点上没有字节码正在执行时，先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁；

如果线程处于活动状态，升级为轻量级锁的状态。

 

轻量级锁：轻量级锁是指当锁是偏向锁的时候，被第二个线程 B 所访问，此时偏向锁就会升级为轻量级锁，线程 B 会通过自旋的形式尝试获取锁，线程不会阻塞，从而提高性能。

当前只有一个等待线程，则该线程将通过自旋进行等待。但是当自旋超过一定的次数时，轻量级锁便会升级为重量级锁；当一个线程已持有锁，另一个线程在自旋，而此时又有第三个线程来访时，轻量级锁也会升级为重量级锁。

 

重量级锁：指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。

重量级锁通过对象内部的监视器（monitor）实现，而其中 monitor 的本质是依赖于底层操作系统的 Mutex Lock 实现，操作系统实现线程之间的切换需要从用户态切换到内核态，切换成本非常高

### 第九章 算法
#### 1.堆排序与快速排序区别以及各自的使用场景
堆排序与快速排序的时间复杂度都是nlogn,但是快排的最差时间复杂度位（n*n），相对于堆排序稍微差了一点。但是从综合性能上分析还是快速排序的性能更好，因为当数据量过大时，堆排序需要对顶节点进行堆化，而不是像快速排序对具局部进行顺序访问，此外堆排序在建堆过程中数据交换次数要远大于快速排序的次数。
#### 2.B+树和红黑树的区别
#### 3.有序数组截断、交换后的查找算法
先查找到截断的位置，拆分成两部分，在这两部分里面使用二分查找？这是肯定可以的，并且找截断位置也使用二分法





